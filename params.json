{"name":"Hive.jl","tagline":"Hive, Spark SQL, Impala client. Based on Thrift and HiveServer2 protocol.","body":"# Hive.jl\r\n\r\nA client for distributed SQL engines that provide a HiveServer2 interface.\r\nE.g.: [Hive](https://hive.apache.org/), [Spark SQL](http://spark.apache.org/sql/), [Impala](http://impala.io/)\r\n\r\n[![Build Status](https://travis-ci.org/JuliaDB/Hive.jl.svg?branch=master)](https://travis-ci.org/JuliaDB/Hive.jl)\r\n\r\n## Connecting\r\n\r\nTo connect to the server, create an instance of HiveSession.\r\n\r\n````\r\nsession = HiveSession()\r\n````\r\n\r\nWithout any parameters, this attempts to connect to a server running on `localhost` port `10000`.\r\nA remote server can be connected to by specifying the hostname and port number.\r\n\r\n````\r\nsession = HiveSession(\"localhost\", 10000)\r\n````\r\n\r\nAs of now only SASL-Plain authentication is supported, without any `qop`. The default implementation\r\nauthenticates with the same user-id as that of the login shell. That can be overridden by providing\r\nan appropriate instance of `HiveAuth`.\r\n\r\n````\r\nsession = HiveSession(\"localhost\", 10000, HiveAuthSASLPlain(\"uid\", \"pwd\", \"zid\"))\r\n````\r\n\r\nThe thrift `TBinaryProtocol` is used by default, which is also the default for most server setups.\r\nOther protocols can be used by specifying the optional named parameter `tprotocol`.\r\nAs of now, `:binary` and `:compact` protocols are supported.\r\n\r\n````\r\nsession = HiveSession(\"localhost\", 10000; tprotocol=:binary)\r\n````\r\n\r\n## Executing Queries\r\n\r\nStatement to be executed can be DML, DDL, SET, etc.\r\n\r\nOptional `config` parameter can have additional keyword parameters that will be passed as configuration \r\nproperties that are overlayed on top of the the existing session configuration before this statement is\r\nexecuted. They apply to this statement only and are not permanent.\r\n\r\nWhen `async` is `true`, execution is asynchronous and a `PendingResult` may be returned.\r\nIf the returned value is a `PendingResult`:\r\n\r\n- `isready` must be called on the `PendingResult` instance to check for completion.\r\n- once ready, calling `result` on it returns `ResultSet`\r\n- when not ready, calling `result` returns the same `PendingResult` instance\r\n\r\n````\r\nrs = execute(session, \"select * from twitter_small where fromid < 100\";\r\n             async=true, config=Dict())\r\nwhile !isready(rs)\r\n    println(\"waiting...\") \r\n    sleep(10)\r\nend\r\nrs = result(rs)\r\n````\r\n\r\n## Working with a Result Set\r\n\r\nResult sets can be iterated upon with iterators and must be closed at the end by calling the `close` method, to release resources.\r\n\r\nTwo kinds of iterators are available as of now:\r\n- **record iterator**: returns a row at a time as a `Tuple`.\r\n- **dataframe iterator**: returns a block of records on each iteration as a `DataFrame` (more efficient)\r\n\r\nCalling `records` results in a record iterator:\r\n\r\n````\r\nrs = execute(session, \"select * from twitter_small where fromid < 100\")\r\nfor rec in records(rs)\r\n   println(rec)\r\nend\r\nclose(rs)\r\n````\r\n\r\nCalling `dataframes` results in a dataframe iterator:\r\n\r\n````\r\nrs = execute(session, \"select * from twitter_small where fromid < 100\")\r\nfor frames in dataframes(rs)\r\n   println(frames)\r\nend\r\nclose(rs)\r\n````\r\n\r\nAll records can be read from a result set by simply calling `dataframe`. This should only be used when the result is sure to fit in memory.\r\n\r\n````\r\nrs = execute(session, \"select * from twitter_small where fromid < 100\")\r\nprintln(dataframe(rs))\r\nclose(rs)\r\n````\r\n\r\n## Fetching Server/Table Metadata\r\n\r\nServer configuration can be fetched by calling `get_info`.\r\nHere, `info_type` is one of the values from the enumeration `InfoType`, e.g. `InfoType.CLI_SERVER_NAME`.\r\n\r\n````\r\ninfo_type = InfoType.CLI_SERVER_NAME\r\ninfo = get_info(session, info_type)\r\n````\r\n\r\nCatalogs, Schemas, TableTypes, Functions, Tables, Columns defined on the server can be listed by calling the appropriate API listed below.\r\nThe results are returned as a DataFrame.\r\n\r\n````\r\n# list all catalogs\r\ncatalogs(session)\r\n\r\n# list all table types configured\r\ntabletypes(session)\r\n\r\n# list all schemas\r\nschemas(session)\r\n\r\n# schema list can be optionally filtered with catalog and schema name\r\nschemas(session; catalog_pattern=\"%\", schema_pattern=\"%\")\r\n\r\n# list all tables\r\ntables(session)\r\n\r\n# table list can be optionally filtered\r\ntables(session; catalog_pattern=\"%\", schema_pattern=\"%\",\r\n       table_pattern=\"%\", table_types=[])\r\n\r\n# list columns\r\ncolumns(session)\r\n\r\n# columns list can be optionally filtered\r\ncolumns(session; catalog=\"\", schema_pattern=\"%\",\r\n        table_pattern=\"%\", column_pattern=\"%\")\r\n\r\n# list functions matching given function name pattern\r\nfunctions(session, \"%\")\r\n\r\n# functions list can be optionally filtered\r\nfunctions(session, \"%\"; catalog=\"\", schema_pattern=\"%\")\r\n````\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}